<!--
   This file is managed by DataStax OpsCenter LifeCycle Manager.
   Manual edits will be overwritten by the next install or configure
   job that runs on this system.
-->

<!--
  ~ Copyright DataStax, Inc.
  ~
  ~ Please see the included license file for details.
  -->
<included>

    <appender name="SparkMasterFileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator>
                <expression>
                    if (mdc == null) return false;
                    String service = (String) mdc.get("service");
                    return service != null &amp;&amp; service.equals("SPARK-MASTER");
                </expression>
            </evaluator>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${SPARK_MASTER_LOG_DIR}/master.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">
            {% comment %}Backported from DSE 5.0.2 to DSE 5.0.1 {% endcomment %}
            <fileNamePattern>${SPARK_MASTER_LOG_DIR}/master.%i.zip</fileNamePattern>
            <minIndex>1</minIndex>
            <maxIndex>20</maxIndex>
        </rollingPolicy>

        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <maxFileSize>20MB</maxFileSize>
        </triggeringPolicy>
        <encoder>
            <pattern>%-5level %date{ISO8601} %F:%L - %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="SparkWorkerFileAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator>
                <expression>
                    if (mdc == null) return false;
                    String service = (String) mdc.get("service");
                    return service != null &amp;&amp; service.equals("SPARK-WORKER");
                </expression>
            </evaluator>
            <onMismatch>DENY</onMismatch>
        </filter>
        <file>${SPARK_WORKER_LOG_DIR}/worker.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">
            {% comment %}Backported from DSE 5.0.2 to DSE 5.0.1 {% endcomment %}
            <fileNamePattern>${SPARK_WORKER_LOG_DIR}/worker.%i.zip</fileNamePattern>
            <minIndex>1</minIndex>
            <maxIndex>20</maxIndex>
        </rollingPolicy>

        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <maxFileSize>{{max-file-size}}MB</maxFileSize>
        </triggeringPolicy>
        <encoder>
            <pattern>%-5level %date{ISO8601} %F:%L - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- Settings to quiet third party logs that are too verbose -->
    <logger name="org.apache.spark.util.logging.FileAppender"
      level="{{org-apache-spark-util-logging-fileappender}}"/>

    <logger name="org.spark_project.jetty"
      level="{{org-spark-project-jetty}}"/>

    <logger name="org.spark_project.jetty.util.component.AbstractLifeCycle"
      level="{{org-spark-project-jetty-util-component-abstractlifecycle}}"/>

    <logger name="org.apache.spark.repl.SparkIMain$exprTyper"
      level="{{org-apache-spark-repl-sparkimain-exprtyper}}"/>

    <logger name="org.apache.spark.repl.SparkILoop$SparkILoopInterpreter"
      level="{{org-apache-spark-repl-sparkiloop-sparkiloopinterpreter}}"/>

    <logger name="org.apache.parquet"
      level="{{org-apache-parquet}}"/>

    <logger name="parquet"
      level="{{parquet}}"/>

    <!-- SPARK-9183: Settings to avoid annoying messages when looking up
        nonexistent UDFs in SparkSQL with Hive support -->
    <logger name="org.apache.hadoop.hive.metastore.RetryingHMSHandler"
      level="{{org-apache-hadoop-hive-metastore-retryinghmshandler}}"/>

    <logger name="org.apache.hadoop.hive.ql.exec.FunctionRegistry"
      level="{{org-apache-hadoop-hive-ql-exec-functionregistry}}"/>

</included>
