<!--
   This file is managed by DataStax OpsCenter LifeCycle Manager.
   Manual edits will be overwritten by the next install or configure
   job that runs on this system.
-->

<!--
  ~ Copyright DataStax, Inc.
  ~
  ~ Please see the included license file for details.
  -->

<configuration scan="false">
    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <target>System.out</target>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>WARN</level>
            <onMatch>DENY</onMatch>
            <onMismatch>NEUTRAL</onMismatch>
        </filter>
        <filter class="ch.qos.logback.classic.filter.LevelFilter">
            <level>ERROR</level>
            <onMatch>DENY</onMatch>
            <onMismatch>NEUTRAL</onMismatch>
        </filter>
        <encoder>
            <pattern>%-5level %date{yyyy-MM-dd HH:mm:ss} %c: %msg%n</pattern>
        </encoder>
    </appender>

    <appender name="STDERR" class="ch.qos.logback.core.ConsoleAppender">
        <target>System.err</target>
        <filter class="ch.qos.logback.classic.filter.ThresholdFilter">
            <level>WARN</level>
        </filter>
        <encoder>
            <pattern>%-5level %date{yyyy-MM-dd HH:mm:ss} %F:%L - %c: %msg%n</pattern>
        </encoder>
    </appender>

    <root level="{{root-level}}">
        <appender-ref ref="STDOUT" />
        <appender-ref ref="STDERR" />
    </root>

    <logger name="com.datastax.driver.core.CodecRegistry" level="ERROR"/>
    <logger name="org.eclipse.jetty" level="{{logger-jetty-level}}"/>

    <!-- Settings to quiet third party logs that are too verbose -->
    <logger name="org.apache.spark.util.logging.FileAppender"
      level="{{org-apache-spark-util-logging-fileappender}}"/>

    <logger name="org.spark_project.jetty"
      level="{{org-spark-project-jetty}}"/>

    <logger name="org.spark_project.jetty.util.component.AbstractLifeCycle"
      level="{{org-spark-project-jetty-util-component-abstractlifecycle}}"/>

    <logger name="org.apache.spark.repl.SparkIMain$exprTyper"
      level="{{org-apache-spark-repl-sparkimain-exprtyper}}"/>

    <logger name="org.apache.spark.repl.SparkILoop$SparkILoopInterpreter"
      level="{{org-apache-spark-repl-sparkiloop-sparkiloopinterpreter}}"/>

    <logger name="org.apache.parquet"
      level="{{org-apache-parquet}}"/>

    <logger name="parquet"
      level="{{parquet}}"/>

    <!-- SPARK-9183: Settings to avoid annoying messages when looking up
        nonexistent UDFs in SparkSQL with Hive support -->
    <logger name="org.apache.hadoop.hive.metastore.RetryingHMSHandler"
      level="{{org-apache-hadoop-hive-metastore-retryinghmshandler}}"/>

    <logger name="org.apache.hadoop.hive.ql.exec.FunctionRegistry"
      level="{{org-apache-hadoop-hive-ql-exec-functionregistry}}"/>

</configuration>
